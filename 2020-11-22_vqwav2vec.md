# VQ-WAV2VEC: SELF-SUPERVISED LEARNING OF DISCRETE SPEECH REPRESENTATIONS

## Abstract
- propose vq-wav2vec to learn discrete representations of audio segments through a wav2vec-style self-supervised context prediction task.

## vq-wav2vec
![](figs/2020-11-22_vqwav2vectramn34for194r_20-00-12-29.png)
- BERT training is done by masking spans of consecutive
discretized speech tokens.

## experiments
![](figs/2020-11-22_vqwav2vectramn5for314r_20-00-12-85.png)